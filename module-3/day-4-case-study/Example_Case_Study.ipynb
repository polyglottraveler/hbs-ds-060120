{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.pexels.com/photos/248152/pexels-photo-248152.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\" style='width:300px'>\n",
    "\n",
    "## Classification Case Study\n",
    "\n",
    "The researchers at SABIC Innovative Plastics US are working on refining the manufacturing process for new polymers. Creating this polymer involves combining 12 materials and 45 mechanical processes (order of processes is unimportant). The prices of ingredients vary as do the amount of time needed for each process done by individual machines that would otherwise be used to make other products. The CSuite requires a pared down list of materials and processes before polymers can go to market. \n",
    "\n",
    "A polymer yield greater than or equal to 41 grams is considered \"high\".\n",
    "\n",
    "You will use logistic regression to create a classification model find the material and process combination that produces high yield."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "#### End Users:\n",
    "\n",
    "- Scientists, budgeting department, CSuite\n",
    "\n",
    "#### True business problem:\n",
    "\n",
    "- Create a model that can, if given data from from repeated chemical manufacturing trials, predict if the polymer yield will be high (worth the money). \n",
    "\n",
    "#### Context:\n",
    "\n",
    "- **False negative** in this context: Predicts that an actually high-yield combination will be low yield.\n",
    "    - **Outcome**: Missed polymer opportunity\n",
    "    \n",
    "- **False positive** in this context: Predicts that an actually low-yield combination will be high yield.\n",
    "\n",
    "    - **Outcome**: Unreliable formula. Takes longer to go to market. Potential company waste.\n",
    "\n",
    "#### Evaluation \n",
    "\n",
    "Which metric (of the ones we've explore so far) would make sense to primarily use as we evaluate our models?\n",
    "\n",
    "- **Accuracy**\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data & take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ChemicalManufacturingProcess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Encode `Yield` into `1/0` depending on if it's equal or greater than 41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X = df.drop(columns = ['Yield'])\n",
    "y = (df['Yield'] >= 41).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeling\n",
    "- impute missing values in columns\n",
    "- scale using max absolute value (this was chosen after trial and error with other scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline preprocessing\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "mscale = MaxAbsScaler()\n",
    "\n",
    "prep = [('imputer', imp), ('scaler', mscale)]\n",
    "\n",
    "pipe = Pipeline(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepped = pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create logistic regression model\n",
    "Using *all* variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg1 = LogisticRegression(random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg1.fit(X_train_prepped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgrg1.predict(X_train_prepped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Check the accuracy of the model. <br>\n",
    "Remember, `sklearn` uses a threshold cutoff of `0.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But is that the **BEST** cutoff?\n",
    "\n",
    "- get predicted probabilities using `X_train_prepped`\n",
    "- use `pipe` to transform `X_test`\n",
    "- predict `y_test_pred_probs` using `lgrg1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_probs = lgrg1.predict_proba(X_train_prepped)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_test\n",
    "X_test_transformed = pipe.transform(X_test)\n",
    "\n",
    "# Get probabilites\n",
    "y_test_pred_probs = lgrg1.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `for` loop to iterate over various thresholds and calculate the accuracy for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['threshold', 'train_acc', 'test_acc'])\n",
    "\n",
    "for x in np.arange(y_train_pred_probs.min(), y_train_pred_probs.max(), 0.01):\n",
    "    placeholder = []\n",
    "    threshold = x\n",
    "    y_pred_train = np.where(y_train_pred_probs > x, 1, 0)\n",
    "    r_pred_test = np.where(y_test_pred_probs > x, 1, 0)\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, r_pred_test)\n",
    "    placeholder = [threshold, train_acc, test_acc]\n",
    "    sample_S = pd.Series(placeholder, index=[\n",
    "                         'threshold', 'train_acc', 'test_acc'])\n",
    "    metrics_df = metrics_df.append(sample_S, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot** the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"Search for Best Threshold using Accuracy\",\n",
    "          fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(y_train_pred_probs.min(), y_train_pred_probs.max())\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(20))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(20))\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(metrics_df['threshold'].data, dtype=float)\n",
    "\n",
    "ax.plot(X_axis, metrics_df['train_acc'], ls='--',\n",
    "        color='g', label='Train Accuracy')\n",
    "ax.plot(X_axis, metrics_df['test_acc'], ls='-',\n",
    "        color='g', label='Test Accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "- Is `.5` the best cutoff?\n",
    "- What is the best choice?\n",
    "- Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## **Advanced** Questions (Optional):\n",
    "\n",
    "- While you're able to predict high yield, are you able to produce a reduced process/materials list?\n",
    "- How would you adjust the `LogisticRegression` arguments to produce a reduced list?\n",
    "- Is the model \"done\"? How would you check to see if multi-collinearity is an issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Coefficients\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(list(lgrg1.coef_[0]),X_train.columns.tolist()):\n",
    "    coef_dict[feat] = coef\n",
    "    \n",
    "# Convert to dataframe so you can sort it\n",
    "coef_df = pd.DataFrame.from_dict(coef_dict, columns =['Coef'], orient='index')\n",
    "coef_df.sort_values(by=['Coef'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set `C` to 0.02 to increase the penalty and perhaps decrease the variable set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg2 = LogisticRegression(C=.02, random_state = 100)\n",
    "lgrg2.fit(X_train_prepped, y_train)\n",
    "y_train_pred_probs = lgrg2.predict_proba(X_train_prepped)[:, 1]\n",
    "y_test_pred_probs = lgrg2.predict_proba(X_test_transformed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check - Did this change the thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns = ['threshold','train_acc', 'test_acc'])\n",
    "\n",
    "for x in np.arange(y_train_pred_probs.min(),y_train_pred_probs.max(), 0.01):\n",
    "    placeholder =[]\n",
    "    threshold = x\n",
    "    y_pred_train = np.where(y_train_pred_probs>x,1,0)\n",
    "    r_pred_test = np.where(y_test_pred_probs>x, 1, 0)\n",
    "    train_acc = accuracy_score(y_train,y_pred_train)\n",
    "    test_acc = accuracy_score(y_test,r_pred_test)\n",
    "    placeholder = [threshold,train_acc, test_acc]\n",
    "    sample_S = pd.Series(placeholder,index = ['threshold','train_acc', 'test_acc'] )\n",
    "    metrics_df = metrics_df.append(sample_S, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"Search for Best Threshold When LASSO Penalty = 0.02\",\n",
    "          fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(y_train_pred_probs.min(), y_train_pred_probs.max())\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(20))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(20))\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(metrics_df['threshold'].data, dtype=float)\n",
    "\n",
    "ax.plot(X_axis, metrics_df['train_acc'], ls='--', color='g', label='Train Accuracy')\n",
    "ax.plot(X_axis, metrics_df['test_acc'], ls='-', color='g', label='Test Accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did it change the coefficients?\n",
    "\n",
    "Did any of them move closer to zero so you can give a reduced list of variables to managment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Coefficients\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(list(lgrg2.coef_[0]),X_train.columns.tolist()):\n",
    "    coef_dict[feat] = coef\n",
    "    \n",
    "# Convert to dataframe so you can sort it\n",
    "coef_df2 = pd.DataFrame.from_dict(coef_dict, columns =['Coef2'], orient='index')\n",
    "coef_df2.sort_values(by=['Coef2'], ascending = False)\n",
    "\n",
    "coef_df.merge(coef_df2,left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.merge(coef_df2,left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for multi-collinearity\n",
    "(do not need to solve it now, only checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = X_train.corr().stack().reset_index()\n",
    "\n",
    "# rename the columns\n",
    "df_corr.columns = ['FEATURE_1', 'FEATURE_2', 'CORRELATION']\n",
    "\n",
    "# create a mask to identify rows with duplicate features as mentioned above\n",
    "mask_dups = (df_corr[['FEATURE_1', 'FEATURE_2']].apply(frozenset, axis=1).duplicated()) | (df_corr['FEATURE_1']==df_corr['FEATURE_2']) \n",
    "\n",
    "# apply the mask to clean the correlation dataframe\n",
    "df_corr = df_corr[~mask_dups]\n",
    "df_corr[abs(df_corr['CORRELATION'])>.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
