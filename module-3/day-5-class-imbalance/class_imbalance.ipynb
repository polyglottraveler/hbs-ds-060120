{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "### Objectives\n",
    "1. Why class imbalances are a problem\n",
    "1. Naive oversampling/undersampling\n",
    "1. Using the “class_weight” parameter (review)\n",
    "1. Advanced methods (SMOTE and ADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification task with a significant difference in proportionality between classes is said to suffer from a Class Imbalance. \n",
    "\n",
    "This is an extremely common problem in real-world settings, and can add significant complexity to the problem. \n",
    "\n",
    "<img src=\"http://harishsivasubramanian.com/wp-content/uploads/2016/09/class.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1 - Cost-Sensitive Learning\n",
    "\n",
    "By default, classifiers in sklearn have a `class_weight` parameter. This is typically set to `None`, which results in a uniform class weight distribution.  \n",
    "\n",
    "Can also be set to ”balanced”, which computes weights using the following code:  \n",
    "`n_samples / (n_calsses * np.bincount(y))`  \n",
    "\n",
    "Weights can also be set manually and passed in as a dictionary, where the weight value determines how much the model should be penalized for getting each class wrong. For example: \n",
    "\n",
    "`class_weight = {0: 0.00001, 1: 0.99999}`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: Naive Over/Undersampling\n",
    "\n",
    "Naive Oversampling/Undersampling are also common ways of dealing with class imbalances. These techniques are not mutually exclusive, and can both be used together. \n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/FEOjd.jpg\" width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Methods: SMOTE & ADASYN\n",
    "\n",
    "A more advanced approach to dealing with class imbalances in Synthetic Data Generation.  The two most popular algorithms for this are SMOTE and ADASYN. \n",
    "\n",
    "These methods start by computing the K-nearest neighbors for in the minority class for each point in the minority class. They then draw a straight line between them, and pick random points on those lines. \n",
    "\n",
    "ADASYN is an improvement on the SMOTE algorithm, because it adds a bit of noise to the points, so they are not linearly correlated with the two real minority samples at each end of the line. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*6UFpLFl59O9e3e38ffTXJQ.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kw0Fk9LsuARF"
   },
   "source": [
    "## Implementation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYf4aWFhuARG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IArpudpbuARI"
   },
   "outputs": [],
   "source": [
    "bankdata = pd.read_csv('https://raw.githubusercontent.com/matbesancon/BankNotes/master/data_banknote_authentication.txt', header=None)\n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpPjwpTmuARK"
   },
   "outputs": [],
   "source": [
    "# our data doesn't have header, so we will manually add that on \n",
    "headers = [\"Variance\", \"Skewness\", \"Curtosis\", \"Entropy\", \"Class\"]\n",
    "bankdata.columns = headers\n",
    "\n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVsLWcXJuARS"
   },
   "source": [
    "__Train-Test-Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHBACO7-uARS"
   },
   "outputs": [],
   "source": [
    "X = bankdata.drop('Class', axis=1)  \n",
    "y = bankdata['Class'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1029, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OCRlyo_uARW"
   },
   "source": [
    "__Scaling Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rnNLsQ9uARX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EABe0PasuARZ"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kH3qqN8tuS2x"
   },
   "source": [
    "__Class Imbalance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6ntyrjF6Xow"
   },
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-t0HOtxpuWV4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiNQOu9yumbI"
   },
   "outputs": [],
   "source": [
    "# How should we implement"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SVMs & PCA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
