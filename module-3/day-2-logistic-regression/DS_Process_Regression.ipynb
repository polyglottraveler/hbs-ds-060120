{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![process](./images/dsprocess.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![why](./images/whybother.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM Process\n",
    "![crisp](./images/crispdm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks of each CRISP step\n",
    "![crisp-tasks](./images/crisptasks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![real_life](./images/real_life.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "![val](./images/validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tts](./images/tts.png)\n",
    "\n",
    "Requirements:\n",
    "- Random sampling of stationary data from the same distribution\n",
    "- Large enough test dataset\n",
    "   -  most common: 80/20\n",
    "    - Make sure at least 1000-3000 samples on test set\n",
    "- Refrain from using test data for model comparison and/or parameter optimisation\n",
    "- Use only on your final model to understand expected performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kfc](./images/kfoldcross.png)\n",
    "\n",
    "- Makes it possible to work with smaller dataset (higher variance)\n",
    "- We expect the mean to be closer to the hidden truth than with TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cvin](./images/cvinsidetts.png)\n",
    "- By nesting CV inside TTS we can compare multiple models/parameters and select the best one without looking at the the test dataset\n",
    "-  The test dataset is still only looked at for your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tvt](./images/tvt.png)\n",
    "\n",
    "- By nesting TTS inside TTS we eliminate the need for training K times\n",
    "- Make sure your validation dataset is big enough (same rules as test)\n",
    "- The test dataset is still only looked at for **your final model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias/Variance tradeoff\n",
    "![bv](./images/bv.png)\n",
    "\n",
    "- The data your model will see after deployment will not be identical to the data it was trained on.\n",
    "- If the magnitude of your errors change a lot depending on the sample, the model may not work well in real life.\n",
    "- This may be due to your model learning the idiosyncrasies of the training data too well and expecting to find them in all other data (Overfitting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting vs Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![undovr](./images/underoverfit.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signs of Fit:\n",
    "\n",
    "- **Overfitting** (high variance of error):\n",
    "    - Very high training performance\n",
    "    - Training performance much higher than validation\n",
    "- **Underfitting** (high average error):\n",
    "    - Poor performance in the training dataset\n",
    "- **Good fit**:\n",
    "    - Training performance just a bit over test performance\n",
    "- **Unknown fit** (assumption violation):\n",
    "    - Test performance higher than Train performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving fitting issues:\n",
    "\n",
    "- When **overfitting**:\n",
    "     - Increase the size of the test dataset (data variance)\n",
    "     - Reduce the complexity of the model (model variance)\n",
    "     - Feature elimination (drop redundant / irrelevant features)\n",
    "- When **underfitting**:\n",
    "     - Increase the size of the training dataset (data bias)\n",
    "     - Increase the complexity of the model (model bias)\n",
    "     - Feature engineering (add new relevant variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![truth](./images/truth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering vs Regularization\n",
    "\n",
    "Take place in this step:\n",
    "\n",
    "![substep](./images/substep.png)\n",
    "\n",
    "#### Feature engineering: (add new relevant variables)\n",
    " - Interaction terms\n",
    " - polynomials\n",
    " - create ratios from existing variables\n",
    " - convert a continuous variable to a bucketed variable...\n",
    " \n",
    "#### Regularization: adds \"bias\" to reduce model complexity\n",
    "- size of \"alpha\" can control for multicolinearity OR reduce variable  set\n",
    "- let's look at [this  link](https://bradleyboehmke.github.io/HOML/regularized-regression.html#ridge) to explore more\n",
    "\n",
    "\n",
    "#### **It is an iterative process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![golden](./images/golden.png)\n",
    "\n",
    "\n",
    "- **Ockham's Razor**: The simpler a model the more likely it will generalise\n",
    "- **Always ask yourself**:: “Will the model be good with a new sample of data?”\n",
    "- Always validate your model on an unseen dataset (test). **And only check it once!!**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivering value\n",
    "\n",
    "Your job is **not** to create high performance models\n",
    "\n",
    "They pay you to _**solve problems**_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which tools do I use?\n",
    "Ridge? lasso? AIC? BIC? -> all  tools to help  us find the best modeling specifications\n",
    "\n",
    "Use Statsmodels? Use Sklearn?\n",
    "\n",
    "Well, it goes  all the way back to:\n",
    "\n",
    "![crispbo](./images/crispbo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a small dataset?\n",
    "Lasso or Ridge isn't likley the best solution\n",
    "\n",
    "### Huge dataset with  over 500  variables\n",
    "probably not the best time to  use statsmodels\n",
    "\n",
    "## Competing model specifications\n",
    "\n",
    "**Model 1**: 4 normalized original variables, 2 interaction terms, one polynomial, one engineered feature<br>\n",
    "\n",
    "**Model 2**: on full list of 12 original variables, 42  interaction terms, squared terms  of  alll variables, a lasso regression reduced the variables set to 6\n",
    "\n",
    "- Which model is better?\n",
    "- which should be used?\n",
    "- What if their R-squareds are the same?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Scenarios:\n",
    "\n",
    "**A**: Want to predict credit scores to be able to give recommendations to people on what to change to get higher scores?\n",
    "\n",
    "**B**: Want to show that your machine  learning shop has reverse enginneered the Equifax regression algorithm  so investors  will fund your  thinktank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts:\n",
    "\n",
    "Statsmodels vs sklearn\n",
    "\n",
    "Regularization  or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
