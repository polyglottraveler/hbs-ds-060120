{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"img/pipelines.png\" style=\"height:450px\">\n",
    "\n",
    "\n",
    "[Image Source](https://towardsdatascience.com/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agenda__\n",
    "\n",
    "- Pipelines and Composite estimators\n",
    "\n",
    "- Why do we need them?\n",
    "\n",
    "- How to use them in sklearn: accessing a particular object in pipe and changing parameters\n",
    "\n",
    "- ROC Curve\n",
    "\n",
    "- Area under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "__What is a Pipeline?__\n",
    "\n",
    "_Transformers:_ Any object with .transform method. Ex: StandardScaler, OneHotEncoder.\n",
    "\n",
    "_Estimators:_ Any object with predict method. Ex: RandomForestClassifier, LinearRegression etc.\n",
    "\n",
    "_Pipelines:_ A tool for combining transformers with estimators. \n",
    "\n",
    "\n",
    "__Why do we need pipelines?__\n",
    "\n",
    "- Convenience and encapsulation\n",
    "\n",
    "Even though we train 10 transformers and 5 estimators we will call fit and predict once.\n",
    "\n",
    "- Joint parameter selection - here emphasize preprocessing part\n",
    "\n",
    "We can put pipelines into gridsearch and find best parameters for all the estimators at once.\n",
    "\n",
    "- Safety\n",
    "\n",
    "Pipelines help avoid leaking statistics from your test data into trained model.\n",
    "\n",
    "[Pipelines and Composite Estimators](https://scikit-learn.org/stable/modules/compose.html#combining-estimators)\n",
    "\n",
    "\n",
    "\n",
    "## Usage of Pipelines\n",
    "\n",
    "The Pipeline is built using a list of (key, value) pairs, where the key is a string containing the name you want to give this step and value is an estimator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [('imputer', SimpleImputer()),\n",
    "              ('scaler', StandardScaler()),\n",
    "              ('clf', LogisticRegression())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Create your own pipeline. You can use the same transformers and estimators with different parameters and 'name'.\n",
    "\n",
    "- You can create a new pipe with a scaler also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_pipe = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also gives us \"make_pipeline\" which is almost the same thing but with make_pipeline you don't have to give names.\n",
    "\n",
    "__Your Turn__\n",
    "\n",
    "-  [Check documentation: 6.1.1.1.1 Construction](https://scikit-learn.org/stable/modules/compose.html) and use `make_pipeline` to construct a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_make_pipe = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing steps\n",
    "\n",
    "We have multiple ways to access and object in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that these will all give the simple imputer object\n",
    "pipe[0]\n",
    "\n",
    "pipe['imputer']\n",
    "\n",
    "pipe.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also access a particular object by named_steps\n",
    "\n",
    "pipe.named_steps.imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can 'slice' pipelines to create sub-pipes\n",
    "\n",
    "pipe[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the parameters\n",
    "\n",
    "Parameters of the estimators in the pipeline can be accessed using the \n",
    "\"estimator__parameter\" syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(clf__C = 10)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dataset info](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset we have 303 patients and 13 independent variables and 1 binary target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are working with classification problems it is always good practice to check the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that approximately 54% of the patients are in the class 0 which refers to 'no presence' of a heart disease. Consequently, 45% of the patients have a heart disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation we split our data into two parts: Train - Test\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=77, stratify=y,\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check number of 1 and 0 in both datasets\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Perfomance Metric for Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Selection vs Model Evaluation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model Selection/Model Comparison: What is the best parameters for a given model. Between different models which one is better models the reality.\n",
    "\n",
    "Ex: If we are working with an app that runs a machine learning algorithm model selection is choosing the process of choosing a final algorithm to deploy.\n",
    "\n",
    "\n",
    "- Model Evaluation: After selecting a 'best' model with model selection how this model will perform in the 'real' case.\n",
    "\n",
    "Ex: Model evaluation is where we want to predict how successful this algorithm will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Available tools in sklearn](https://scikit-learn.org/stable/model_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= 'img/table.png' width = 450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep Before Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A good blog post on handling categorical variables](https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_Data_Preprocessing-Missing-Data-Categorical-Data.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Convert Categorical Variables to OneHotEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder object. This will help us to convert\n",
    "# categorical variables to new columns\n",
    "encoder = None\n",
    "\n",
    "# Create an columntransformer object.\n",
    "# This will help us to merge transformed columns\n",
    "# with the rest of the dataset.\n",
    "catvars = None\n",
    "ct = ColumnTransformer(???)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Don't forget!!__\n",
    "\n",
    "- Apply the same transformations to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = ct.transform(X_test)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scaling Features__ \n",
    "\n",
    "-- Let's go back to the column transformer.\n",
    "\n",
    "[Different Scalers and Their Effect on Data](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X, axis=0)\n",
    "\n",
    "# What do you expect if you check the means of X_test? Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Check sklearn for documentation of Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "\n",
    "[For solvers](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='none', max_iter=10000)\n",
    "log_reg.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is this score?\n",
    "print(log_reg.score(X, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X)\n",
    "\n",
    "score = log_reg.score(X, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5,\n",
    "            square=True, cmap='Blues')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size=15)\n",
    "plt.savefig('toy_Digits_ConfusionSeabornCodementor.png')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves for Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_vanilla = LogisticRegression(penalty='none', max_iter=10000)\n",
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l2', C=0.01, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_vanilla.fit(X, y_train)\n",
    "\n",
    "y_probs_vanilla = log_reg_vanilla.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_l2.fit(X, y_train)\n",
    "y_probs_l2 = log_reg_l2.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_v, tpr_v, thresholds_v = roc_curve(y_train, y_probs_vanilla[:,1])\n",
    "fpr_l2, tpr_l2, thresholds_l2 = roc_curve(y_train, y_probs_l2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "\n",
    "plot_roc_curve(fpr_v, tpr_v, label='Vanilla')\n",
    "plot_roc_curve(fpr_l2, tpr_l2, label='L2-Penalty')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can measure the __A__rea __U__nder __C__urve scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roc_auc_score(y_train, y_probs_vanilla[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_probs_l2[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Default Measure (in most prebuilt models) - Accuracy\n",
    "\n",
    "$$ \\frac{(TP + TN)}{(TP + FP + TN + FN)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category definitions - possible outcomes in binary classification\n",
    "\n",
    "- TP = True Positive (class 1 correctly classified as class 1) - e.g. Patient with cancer tests positive for cancer\n",
    "- TN = True Negative (class 0 correctly classified as class 0) - e.g. Patient without cancer tests negative for cancer\n",
    "- FP = False Positive (class 0 incorrectly classified as class 1) - e.g. Patient without cancer tests positive for cancer\n",
    "- FN = False Negative (class 1 incorrectly classified as class 0) - e.g. Patient with cancer tests negative for cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ \\text{Possible misclassifications} $$\n",
    "\n",
    "<img src='./img/type-1-type-2.jpg' width=400/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that Logistic Regression gives probability predictions for each class, in addition to the final classification. By default, threshold for the prediction is set to 0.5, but we can adjust that threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The AUC / ROC curve (Area Under Curve of the Receiver Operating Characteristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/pop-curve.png' width=500/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cross Validation Scores for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='none', max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = cross_val_score(log_reg, X, y_train, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
