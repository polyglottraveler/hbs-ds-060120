{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Regression Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why regularize?\n",
    "\n",
    "- Reduce complexity\n",
    "- Reduce the chance of overfitting\n",
    "- Reduce model variance at the expense of introducing small bias\n",
    "- Increase model interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What even is L1 or L2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review:\n",
    "\n",
    "What is L1 Regularization (LASSO) good for?\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "What is L2 Regularization (Ridge) good for?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![baby penguin gif from Giphy](https://media.giphy.com/media/RiJuDMqd6vDgfPrZN2/giphy.gif)\n",
    "\n",
    "Let's hang out with penguins some more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up this dataset - two rows have quite a few null values, and 11 total do not have a value for `sex`, so let's drop rows where any data is null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[['species','island','sex']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the `gender`, `species` or `island` data we need to render those strings as numbers - since there are only 2-3 unique values per column, let's simply one-hot-encode those columns (aka turn the columns into a series of binary indicators).\n",
    "\n",
    "Using Pandas' `get_dummies` : https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode our three 'object' columns\n",
    "data_num = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that Pandas' `get_dummies` does not automatically drop one of the columns - even though the two `sex` columns, `sex_FEMALE` and `sex_MALE`, are simply inverses of each other, and thus one of those columns contains the same amount of information as having both of those columns, it keeps both. That's fine for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_num.corr().abs())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this is to predict body mass, `body_mass_g`, so let's define our X and y and perform a train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train/test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling our Data:\n",
    "\n",
    "When we introduced scaling variables last week, we talked about how some models require that we scale or standardize variables before using those models - Ridge and LASSO regression are two of those models!\n",
    "\n",
    "Why? Because both Ridge and LASSO look at the coefficients of a linear regression model to penalize those coefficients. Coefficients of linear models are highly dependent on the values of those models - making sure they're properly scaled will make sure that our model penalizes actually useless columns, instead of just thinking those columns are useless because the data isn't properly scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our scaler on training data, then fit to testing\n",
    "X_train_scaled = None\n",
    "X_test_scaled = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear regression model\n",
    "lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model on our scaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_train_pred = lr.predict(X_train_scaled)\n",
    "y_test_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"Training Scores:\")\n",
    "print(f\"R2: {r2_score(y_train, y_train_pred)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_train_pred)}\")\n",
    "print(\"---\")\n",
    "print(\"Testing Scores:\")\n",
    "print(f\"R2: {r2_score(y_test, y_test_pred)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Norm: LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a lasso regression model\n",
    "lasso = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your new L1 model -  on the scaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate=\n",
    "y_train_pred_l1 = lasso.predict(X_train_scaled)\n",
    "y_test_pred_l1 = lasso.predict(X_test_scaled)\n",
    "\n",
    "print(\"Training Scores:\")\n",
    "print(f\"R2: {r2_score(y_train, y_train_pred_l1)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_train_pred_l1)}\")\n",
    "print(\"---\")\n",
    "print(\"Testing Scores:\")\n",
    "print(f\"R2: {r2_score(y_test, y_test_pred_l1)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_test_pred_l1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember - what's the benefit of using LASSO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lr.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lr.intercept_))\n",
    "print(\"---\")\n",
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Norm: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a lasso regression model\n",
    "ridge = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your new L2 model -  on the scaled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_train_pred_l2 = ridge.predict(X_train_scaled)\n",
    "y_test_pred_l2 = ridge.predict(X_test_scaled)\n",
    "\n",
    "print(\"Training Scores:\")\n",
    "print(f\"R2: {r2_score(y_train, y_train_pred_l2)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_train_pred_l2)}\")\n",
    "print(\"---\")\n",
    "print(\"Testing Scores:\")\n",
    "print(f\"R2: {r2_score(y_test, y_test_pred_l2)}\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_test_pred_l2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lr.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lr.intercept_))\n",
    "print(\"---\")\n",
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = {}\n",
    "for loc, col in enumerate(data_num.columns):\n",
    "    coef_dict[col] = {\"Unpenalized\": lr.coef_[loc-1],\n",
    "                      \"LASSO\": lasso.coef_[loc-1],\n",
    "                      \"Ridge\": ridge.coef_[loc-1]}\n",
    "pd.DataFrame.from_dict(coef_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Levels??\n",
    "\n",
    "We started with the **hyperparameter** alpha set to `0.5` for both our LASSO and Ridge Models: now let's play around with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [Stats course resource from Penn State](https://online.stat.psu.edu/stat508/lesson/5), going into detail about Regression Shrinkage Methods - aka regularization. This is pretty technical, and the code is in R, but goes into good detail about the motivation of why we do this and how this works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
